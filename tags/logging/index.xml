<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>logging on 菠萝头</title><link>https://blog.boluotou.tech/tags/logging/</link><description>Recent content in logging on 菠萝头</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 14 Aug 2022 23:09:08 +0800</lastBuildDate><atom:link href="https://blog.boluotou.tech/tags/logging/index.xml" rel="self" type="application/rss+xml"/><item><title>一套充分利用本地机器的日志中心架构</title><link>https://blog.boluotou.tech/post/20220814-logging-center-architecture/</link><pubDate>Sun, 14 Aug 2022 23:09:08 +0800</pubDate><guid>https://blog.boluotou.tech/post/20220814-logging-center-architecture/</guid><description>&lt;p>&lt;img src="https://blog.boluotou.tech/logging-architecture.png"
loading="lazy"
alt="logging-architecture"
>&lt;/p>
&lt;ol>
&lt;li>服务搭在k8s上，起一个DaemonSet使用Fluent-Bit收集所有日志，发到Kafka（这个kafka可以是云服务商提供的，或者是自建的，但无论如何要能被本地机器访问）。&lt;/li>
&lt;li>本地机器也搞一个k8s集群，先搭ElasticSearch，再由Logstash收集Kafka中的日志（有插件）插入到es里，最后由Kibana读取。&lt;/li>
&lt;/ol>
&lt;p>具体命令懒得写了，大家自己研究吧。&lt;/p></description></item></channel></rss>